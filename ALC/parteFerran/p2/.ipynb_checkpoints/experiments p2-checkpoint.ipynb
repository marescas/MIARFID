{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(path):\n",
    "    # load data\n",
    "    train = open(path).read()\n",
    "    train = BeautifulSoup(train, 'lxml')\n",
    "    tweets = [twt.text for twt in train.findAll('content')]\n",
    "    labels = [labs.text for labs in train.findAll('value')]\n",
    "    ids = [labs.text for labs in train.findAll('tweetid')] \n",
    "    return tweets, labels, ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data_test(path):\n",
    "    # load data\n",
    "    train = open(path).read()\n",
    "    train = BeautifulSoup(train, 'lxml')\n",
    "    tweets = [twt.text for twt in train.findAll('content')]\n",
    "    ids = [labs.text for labs in train.findAll('tweetid')] \n",
    "    return tweets, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuitTrain,polTrain,idTrain =parse_data('TASS2017_T1_training.xml')\n",
    "tuitDev,polDev,idDev =parse_data('TASS2017_T1_development.xml')\n",
    "tuitTest,idTest =  parse_data_test(\"TASS2017_T1_test.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TweetTokenizer(strip_handles=False, reduce_len=True, preserve_case=False)\n",
    "tuitTrainClean = list(map(\" \".join,map(tokenizer.tokenize,tuitTrain)))\n",
    "tuitDevClean = list(map(\" \".join,map(tokenizer.tokenize,tuitDev)))\n",
    "tuitTestClean = list(map(\" \".join,map(tokenizer.tokenize,tuitTest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 980 candidates, totalling 4900 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed:   19.1s\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed:   33.6s\n",
      "[Parallel(n_jobs=-1)]: Done 997 tasks      | elapsed:   57.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1442 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1969 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2576 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 3265 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done 4885 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done 4900 out of 4900 | elapsed:  5.4min finished\n",
      "/Users/marcosesteve/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/Users/marcosesteve/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/marcosesteve/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('tfidf',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_word...\n",
       "                                                           warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'clf__C': [1, 10, 100, 1000, 10000],\n",
       "                         'tfidf__analyzer': ['char_wb'],\n",
       "                         'tfidf__max_df': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
       "                         'tfidf__min_df': [1, 2, 3, 5],\n",
       "                         'tfidf__ngram_range': [(1, 2), (1, 3), (2, 3), (3, 4),\n",
       "                                                (3, 5), (3, 6), (4, 5)]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1_macro', verbose=2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "        (\"tfidf\",TfidfVectorizer()),\n",
    "        (\"clf\",LogisticRegression())\n",
    "])\n",
    "    \n",
    "parameters = {\"tfidf__ngram_range\" : [(1,2),(1,3),(2,3),(3,4),(3,5),(3,6),(4,5)]\n",
    "                  ,\"tfidf__max_df\":[0.3,0.4,0.5,0.6,0.7,0.8,0.9],\n",
    "                  \"tfidf__min_df\":[1,2,3,5],\n",
    "                  \"tfidf__analyzer\":[\"char_wb\"],\n",
    "                  #'clf__kernel':['linear', 'rbf'],\n",
    "                  'clf__C':[1,10,100,1000,10000]}\n",
    "clf = GridSearchCV(pipe, parameters,cv=5,n_jobs=-1,verbose=2,scoring=\"f1_macro\")\n",
    "clf.fit(tuitTrainClean, polTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3978413396036023"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__C': 10,\n",
       " 'tfidf__analyzer': 'char_wb',\n",
       " 'tfidf__max_df': 0.3,\n",
       " 'tfidf__min_df': 2,\n",
       " 'tfidf__ngram_range': (4, 5)}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcosesteve/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "        (\"tfidf\",TfidfVectorizer(max_df=0.4,min_df=2,ngram_range=(4,5),analyzer=\"char_wb\")),\n",
    "        (\"clf\",svm.SVC(C=10000,kernel=\"rbf\"))\n",
    "])\n",
    "pipe.fit(tuitTrainClean, polTrain)\n",
    "prediction = pipe.predict(tuitTestClean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"svm_marcos.txt\",\"w\") as f:\n",
    "    for id, pred in zip(idTest,prediction):\n",
    "        f.write(\"%s\\t%s\\n\" %(id,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.58      0.80      0.67       219\n",
      "         NEU       0.21      0.07      0.11        69\n",
      "        NONE       0.48      0.21      0.29        62\n",
      "           P       0.64      0.62      0.63       156\n",
      "\n",
      "    accuracy                           0.57       506\n",
      "   macro avg       0.48      0.42      0.42       506\n",
      "weighted avg       0.53      0.57      0.53       506\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(polDev, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'NONE': 139, 'N': 418, 'P': 318, 'NEU': 133})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(polTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
